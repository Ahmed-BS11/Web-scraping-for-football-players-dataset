{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Input, Embedding, Flatten, Dense, Concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.model_selection import train_test_split\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-10T07:40:39.151817Z","iopub.execute_input":"2023-05-10T07:40:39.152808Z","iopub.status.idle":"2023-05-10T07:40:51.099177Z","shell.execute_reply.started":"2023-05-10T07:40:39.152758Z","shell.execute_reply":"2023-05-10T07:40:51.098053Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Load the dataset\ndata = pd.read_csv(\"/kaggle/input/mydata/MYDATA.csv\")\ndata.info()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:43:29.068522Z","iopub.execute_input":"2023-05-08T19:43:29.069134Z","iopub.status.idle":"2023-05-08T19:43:29.232868Z","shell.execute_reply.started":"2023-05-08T19:43:29.069100Z","shell.execute_reply":"2023-05-08T19:43:29.231594Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 30066 entries, 0 to 30065\nData columns (total 30 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   Unnamed: 0             30066 non-null  int64  \n 1   name                   30066 non-null  object \n 2   age                    30066 non-null  int64  \n 3   position               30066 non-null  object \n 4   Country                30066 non-null  object \n 5   MarketValue            30066 non-null  float64\n 6   PreviousTeam           30066 non-null  object \n 7   LeagueOfPreviousTeam   30066 non-null  object \n 8   CountryOfPreviousTeam  30066 non-null  object \n 9   Fee                    30066 non-null  float64\n 10  YearOfTranfert         30066 non-null  int64  \n 11  NewTeam                30066 non-null  object \n 12  LeagueOfNewTeam        30066 non-null  object \n 13  CountryOfNewTeam       30066 non-null  object \n 14  Height                 30066 non-null  float64\n 15  Squad                  30066 non-null  int64  \n 16  Appearances            30066 non-null  int64  \n 17  PPG                    30066 non-null  float64\n 18  Goals                  30066 non-null  int64  \n 19  Assists                30066 non-null  int64  \n 20  OwnGoals               30066 non-null  int64  \n 21  SubsON                 30066 non-null  int64  \n 22  SubsOFF                30066 non-null  int64  \n 23  YellowCards            30066 non-null  int64  \n 24  SecondYellowCards      30066 non-null  int64  \n 25  RedCards               30066 non-null  int64  \n 26  PenaltyGoals           30066 non-null  int64  \n 27  MinutesPerGoal         30066 non-null  int64  \n 28  MinutesPlayed          30066 non-null  int64  \n 29  PlaceOfBirth           30066 non-null  object \ndtypes: float64(4), int64(16), object(10)\nmemory usage: 6.9+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"\nle = LabelEncoder()\ndata[\"name1\"] = le.fit_transform(data[\"name\"])\ndata[\"NewTeam1\"] = le.fit_transform(data[\"NewTeam\"])\ndata[\"position1\"] = le.fit_transform(data[\"position\"])\ndata[\"Country1\"] = le.fit_transform(data[\"Country\"])\ndata[\"PreviousTeam1\"] = le.fit_transform(data[\"PreviousTeam\"])\ndata[\"LeagueOfPreviousTeam1\"] = le.fit_transform(data[\"LeagueOfPreviousTeam\"])\ndata[\"CountryOfPreviousTeam1\"] = le.fit_transform(data[\"CountryOfPreviousTeam\"])\ndata[\"LeagueOfNewTeam1\"] = le.fit_transform(data[\"LeagueOfNewTeam\"])\ndata[\"CountryOfNewTeam1\"] = le.fit_transform(data[\"CountryOfNewTeam\"])\ndata['name1']","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:43:29.235266Z","iopub.execute_input":"2023-05-08T19:43:29.235993Z","iopub.status.idle":"2023-05-08T19:43:29.351752Z","shell.execute_reply.started":"2023-05-08T19:43:29.235944Z","shell.execute_reply":"2023-05-08T19:43:29.350654Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0         3516\n1         3448\n2         1153\n3        11974\n4         1301\n         ...  \n30061     6541\n30062     6335\n30063     5537\n30064    11705\n30065    11715\nName: name1, Length: 30066, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Split the data into train and test sets\n#data = pd.get_dummies(data, columns=[\"position\", \"Country\", \"PreviousTeam\", \"LeagueOfPreviousTeam\", \"CountryOfPreviousTeam\", \"LeagueOfNewTeam\", \"CountryOfNewTeam\"])\n\n\nX = data.drop(\"PPG\", axis=1)\ny = data[\"PPG\"]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:43:29.353722Z","iopub.execute_input":"2023-05-08T19:43:29.354194Z","iopub.status.idle":"2023-05-08T19:43:29.382969Z","shell.execute_reply.started":"2023-05-08T19:43:29.354128Z","shell.execute_reply":"2023-05-08T19:43:29.382044Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\"\"\"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n# Assume 'X_train' and 'X_test' are numpy arrays, and the categorical column is at index 0\ncategorical_col_index = 1\n\n# Create the encoder object\nencoder = OneHotEncoder(sparse=False)\n\n# Fit the encoder to the training data and transform both the training and test data\nX_train_encoded = encoder.fit_transform(X_train[:, categorical_col_index].reshape(-1, 1))\nX_test_encoded = encoder.transform(X_test[:, categorical_col_index].reshape(-1, 1))\n\n# Concatenate the encoded data with the non-categorical data\nX_train_final = np.concatenate([X_train_encoded, X_train[:, 1:]], axis=1)\nX_test_final = np.concatenate([X_test_encoded, X_test[:, 1:]], axis=1)\n\n# Scale the data\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_final)\nX_test_scaled = scaler.transform(X_test_final)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:43:29.386068Z","iopub.execute_input":"2023-05-08T19:43:29.386634Z","iopub.status.idle":"2023-05-08T19:43:29.394444Z","shell.execute_reply.started":"2023-05-08T19:43:29.386588Z","shell.execute_reply":"2023-05-08T19:43:29.393250Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"\"from sklearn.preprocessing import OneHotEncoder\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# Assume 'X_train' and 'X_test' are numpy arrays, and the categorical column is at index 0\\ncategorical_col_index = 1\\n\\n# Create the encoder object\\nencoder = OneHotEncoder(sparse=False)\\n\\n# Fit the encoder to the training data and transform both the training and test data\\nX_train_encoded = encoder.fit_transform(X_train[:, categorical_col_index].reshape(-1, 1))\\nX_test_encoded = encoder.transform(X_test[:, categorical_col_index].reshape(-1, 1))\\n\\n# Concatenate the encoded data with the non-categorical data\\nX_train_final = np.concatenate([X_train_encoded, X_train[:, 1:]], axis=1)\\nX_test_final = np.concatenate([X_test_encoded, X_test[:, 1:]], axis=1)\\n\\n# Scale the data\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train_final)\\nX_test_scaled = scaler.transform(X_test_final)\""},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\"\"\"\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:43:29.395809Z","iopub.execute_input":"2023-05-08T19:43:29.396081Z","iopub.status.idle":"2023-05-08T19:43:29.438526Z","shell.execute_reply.started":"2023-05-08T19:43:29.396055Z","shell.execute_reply":"2023-05-08T19:43:29.437331Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                name  age            position    Country  \\\n0           0     Erling Haaland    21      Centre-Forward     Norway   \n1           1      Enzo Fern?dez    22    Central Midfield  Argentina   \n2           2             Antony    22        Right Winger     Brazil   \n3           3      Wesley Fofana    21         Centre-Back     France   \n4           4  Aur?ien Tchouam?i    22  Defensive Midfield     France   \n\n   MarketValue       PreviousTeam LeagueOfPreviousTeam CountryOfPreviousTeam  \\\n0        150.0  Borussia Dortmund           Bundesliga               Germany   \n1         55.0         SL Benfica        Liga Portugal              Portugal   \n2         35.0     Ajax Amsterdam           Eredivisie           Netherlands   \n3         40.0     Leicester City       Premier League               England   \n4         60.0          AS Monaco              Ligue 1                Monaco   \n\n     Fee  ...  PlaceOfBirth  name1 NewTeam1 position1  Country1  \\\n0   60.0  ...         Leeds   3516      935         4       112   \n1  121.0  ...      SanMart?   3448      355         2         4   \n2   95.0  ...       S?Paulo   1153      938        12        17   \n3   80.4  ...     Marseille  11974      355         3        50   \n4   80.0  ...         Rouen   1301     1140         6        50   \n\n   PreviousTeam1  LeagueOfPreviousTeam1  CountryOfPreviousTeam1  \\\n0            212                     37                      28   \n1           1175                    122                      61   \n2             72                     61                      55   \n3            866                    161                      23   \n4             54                    132                      52   \n\n   LeagueOfNewTeam1  CountryOfNewTeam1  \n0               259                 24  \n1               259                 24  \n2               259                 24  \n3               259                 24  \n4               162                 69  \n\n[5 rows x 39 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>name</th>\n      <th>age</th>\n      <th>position</th>\n      <th>Country</th>\n      <th>MarketValue</th>\n      <th>PreviousTeam</th>\n      <th>LeagueOfPreviousTeam</th>\n      <th>CountryOfPreviousTeam</th>\n      <th>Fee</th>\n      <th>...</th>\n      <th>PlaceOfBirth</th>\n      <th>name1</th>\n      <th>NewTeam1</th>\n      <th>position1</th>\n      <th>Country1</th>\n      <th>PreviousTeam1</th>\n      <th>LeagueOfPreviousTeam1</th>\n      <th>CountryOfPreviousTeam1</th>\n      <th>LeagueOfNewTeam1</th>\n      <th>CountryOfNewTeam1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Erling Haaland</td>\n      <td>21</td>\n      <td>Centre-Forward</td>\n      <td>Norway</td>\n      <td>150.0</td>\n      <td>Borussia Dortmund</td>\n      <td>Bundesliga</td>\n      <td>Germany</td>\n      <td>60.0</td>\n      <td>...</td>\n      <td>Leeds</td>\n      <td>3516</td>\n      <td>935</td>\n      <td>4</td>\n      <td>112</td>\n      <td>212</td>\n      <td>37</td>\n      <td>28</td>\n      <td>259</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Enzo Fern?dez</td>\n      <td>22</td>\n      <td>Central Midfield</td>\n      <td>Argentina</td>\n      <td>55.0</td>\n      <td>SL Benfica</td>\n      <td>Liga Portugal</td>\n      <td>Portugal</td>\n      <td>121.0</td>\n      <td>...</td>\n      <td>SanMart?</td>\n      <td>3448</td>\n      <td>355</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1175</td>\n      <td>122</td>\n      <td>61</td>\n      <td>259</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Antony</td>\n      <td>22</td>\n      <td>Right Winger</td>\n      <td>Brazil</td>\n      <td>35.0</td>\n      <td>Ajax Amsterdam</td>\n      <td>Eredivisie</td>\n      <td>Netherlands</td>\n      <td>95.0</td>\n      <td>...</td>\n      <td>S?Paulo</td>\n      <td>1153</td>\n      <td>938</td>\n      <td>12</td>\n      <td>17</td>\n      <td>72</td>\n      <td>61</td>\n      <td>55</td>\n      <td>259</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Wesley Fofana</td>\n      <td>21</td>\n      <td>Centre-Back</td>\n      <td>France</td>\n      <td>40.0</td>\n      <td>Leicester City</td>\n      <td>Premier League</td>\n      <td>England</td>\n      <td>80.4</td>\n      <td>...</td>\n      <td>Marseille</td>\n      <td>11974</td>\n      <td>355</td>\n      <td>3</td>\n      <td>50</td>\n      <td>866</td>\n      <td>161</td>\n      <td>23</td>\n      <td>259</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Aur?ien Tchouam?i</td>\n      <td>22</td>\n      <td>Defensive Midfield</td>\n      <td>France</td>\n      <td>60.0</td>\n      <td>AS Monaco</td>\n      <td>Ligue 1</td>\n      <td>Monaco</td>\n      <td>80.0</td>\n      <td>...</td>\n      <td>Rouen</td>\n      <td>1301</td>\n      <td>1140</td>\n      <td>6</td>\n      <td>50</td>\n      <td>54</td>\n      <td>132</td>\n      <td>52</td>\n      <td>162</td>\n      <td>69</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 39 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\n# Define input layers\nuser_input = Input(shape=[1])\nitem_input = Input(shape=[1])\nage_input = Input(shape=[1])\nmv_input = Input(shape=[1])\nfee_input = Input(shape=[1])\nmins_input = Input(shape=[1])\n\n# Define embedding layers\nuser_emb = Flatten()(Embedding(input_dim=len(data[\"name\"].unique())+1, output_dim=10)(user_input))\nitem_emb = Flatten()(Embedding(input_dim=len(data[\"NewTeam\"].unique())+1, output_dim=10)(item_input))\n\n# Concatenate embedding layers and input layers\nconcat = Concatenate()([user_emb, item_emb, age_input, mv_input, fee_input, mins_input])\n\n# Define hidden layers\nfc1 = Dense(64, activation='relu')(concat)\nfc2 = Dense(32, activation='relu')(fc1)\noutput = Dense(1)(fc2)\n\n# Define model\nmodel = Model(inputs=[user_input, item_input, age_input, mv_input, fee_input, mins_input], outputs=output)\n\n# Compile model\nmodel.compile(loss='mse', optimizer=Adam(lr=0.001))\nmodel.summary()\n# Train model\nhistory = model.fit([data[\"name1\"], data[\"NewTeam1\"], data[\"age\"], data[\"MarketValue\"], data[\"Fee\"], data[\"MinutesPlayed\"]], data[\"PPG\"], epochs=10, validation_split=0.2)\n\n# Evaluate model\nmodel.evaluate([data[\"name1\"], data[\"NewTeam1\"], data[\"age\"], data[\"MarketValue\"], data[\"Fee\"], data[\"MinutesPlayed\"]], data[\"PPG\"])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:43:29.439940Z","iopub.execute_input":"2023-05-08T19:43:29.440364Z","iopub.status.idle":"2023-05-08T19:43:57.080090Z","shell.execute_reply.started":"2023-05-08T19:43:29.440315Z","shell.execute_reply":"2023-05-08T19:43:57.078856Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, 1)]          0           []                               \n                                                                                                  \n input_2 (InputLayer)           [(None, 1)]          0           []                               \n                                                                                                  \n embedding (Embedding)          (None, 1, 10)        123520      ['input_1[0][0]']                \n                                                                                                  \n embedding_1 (Embedding)        (None, 1, 10)        15000       ['input_2[0][0]']                \n                                                                                                  \n flatten (Flatten)              (None, 10)           0           ['embedding[0][0]']              \n                                                                                                  \n flatten_1 (Flatten)            (None, 10)           0           ['embedding_1[0][0]']            \n                                                                                                  \n input_3 (InputLayer)           [(None, 1)]          0           []                               \n                                                                                                  \n input_4 (InputLayer)           [(None, 1)]          0           []                               \n                                                                                                  \n input_5 (InputLayer)           [(None, 1)]          0           []                               \n                                                                                                  \n input_6 (InputLayer)           [(None, 1)]          0           []                               \n                                                                                                  \n concatenate (Concatenate)      (None, 24)           0           ['flatten[0][0]',                \n                                                                  'flatten_1[0][0]',              \n                                                                  'input_3[0][0]',                \n                                                                  'input_4[0][0]',                \n                                                                  'input_5[0][0]',                \n                                                                  'input_6[0][0]']                \n                                                                                                  \n dense (Dense)                  (None, 64)           1600        ['concatenate[0][0]']            \n                                                                                                  \n dense_1 (Dense)                (None, 32)           2080        ['dense[0][0]']                  \n                                                                                                  \n dense_2 (Dense)                (None, 1)            33          ['dense_1[0][0]']                \n                                                                                                  \n==================================================================================================\nTotal params: 142,233\nTrainable params: 142,233\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/10\n752/752 [==============================] - 4s 3ms/step - loss: 268.5768 - val_loss: 0.2403\nEpoch 2/10\n752/752 [==============================] - 2s 3ms/step - loss: 0.2417 - val_loss: 0.2391\nEpoch 3/10\n752/752 [==============================] - 2s 3ms/step - loss: 0.1894 - val_loss: 0.2802\nEpoch 4/10\n752/752 [==============================] - 2s 3ms/step - loss: 0.1853 - val_loss: 0.2789\nEpoch 5/10\n752/752 [==============================] - 2s 3ms/step - loss: 0.3273 - val_loss: 0.2717\nEpoch 6/10\n752/752 [==============================] - 2s 3ms/step - loss: 0.4674 - val_loss: 0.4355\nEpoch 7/10\n752/752 [==============================] - 2s 3ms/step - loss: 2.0682 - val_loss: 0.3019\nEpoch 8/10\n752/752 [==============================] - 2s 3ms/step - loss: 3.5098 - val_loss: 0.8226\nEpoch 9/10\n752/752 [==============================] - 2s 3ms/step - loss: 1.3384 - val_loss: 3.6333\nEpoch 10/10\n752/752 [==============================] - 2s 3ms/step - loss: 3.5183 - val_loss: 0.7362\n940/940 [==============================] - 1s 2ms/step - loss: 0.6233\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0.6233119368553162"},"metadata":{}}]},{"cell_type":"code","source":"data[\"name1\"]\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:43:57.081490Z","iopub.execute_input":"2023-05-08T19:43:57.081844Z","iopub.status.idle":"2023-05-08T19:43:57.090530Z","shell.execute_reply.started":"2023-05-08T19:43:57.081812Z","shell.execute_reply":"2023-05-08T19:43:57.089361Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0         3516\n1         3448\n2         1153\n3        11974\n4         1301\n         ...  \n30061     6541\n30062     6335\n30063     5537\n30064    11705\n30065    11715\nName: name1, Length: 30066, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#target_player = 11974\nplayer_ids=data['name1']\n#target_player_id = le.transform([target_player])[0]\n\n# Get the embeddings for all players\nplayer_embs = model.get_layer(\"embedding_9\")(tf.constant(player_ids, dtype=tf.int32)).numpy()\n\n# Get the embedding for the target player\ntarget_player_emb = player_embs[11974]\n\n# Compute the cosine similarity between the target player and all other players\nsimilarities = np.dot(player_embs, target_player_emb) / (np.linalg.norm(player_embs, axis=1) * np.linalg.norm(target_player_emb))\n\n# Get the top-k most similar players\nk = 10\ntop_k_indices = similarities.argsort()[::-1][1:k+1]\ntop_k_players = le.inverse_transform(player_ids[top_k_indices])\n\n# Print the recommended players\nprint(f\"Top-{k} recommended players for {target_player}:\")\nfor i, player in enumerate(top_k_players):\n    print(f\"{i+1}. {player}\")","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:43:57.092135Z","iopub.execute_input":"2023-05-08T19:43:57.092668Z","iopub.status.idle":"2023-05-08T19:43:57.488014Z","shell.execute_reply.started":"2023-05-08T19:43:57.092605Z","shell.execute_reply":"2023-05-08T19:43:57.486318Z"},"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/362536712.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Get the embeddings for all players\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplayer_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embedding_9\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Get the embedding for the target player\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   3352\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3353\u001b[0m             raise ValueError(\n\u001b[0;32m-> 3354\u001b[0;31m                 \u001b[0;34mf\"No such layer: {name}. Existing layers are: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3355\u001b[0m                 \u001b[0;34mf\"{list(layer.name for layer in self.layers)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: No such layer: embedding_9. Existing layers are: ['input_1', 'input_2', 'embedding', 'embedding_1', 'flatten', 'flatten_1', 'input_3', 'input_4', 'input_5', 'input_6', 'concatenate', 'dense', 'dense_1', 'dense_2']."],"ename":"ValueError","evalue":"No such layer: embedding_9. Existing layers are: ['input_1', 'input_2', 'embedding', 'embedding_1', 'flatten', 'flatten_1', 'input_3', 'input_4', 'input_5', 'input_6', 'concatenate', 'dense', 'dense_1', 'dense_2'].","output_type":"error"}]},{"cell_type":"code","source":"\n# Make recommendations\nuser_ids = data[\"name\"].unique()\nitem_ids = data[\"NewTeam\"].unique()\nuser_id_map = dict(zip(user_ids, range(len(user_ids))))\nitem_id_map = dict(zip(item_ids, range(len(item_ids))))\n#print(user_id_map)\nuser=user_ids[0]\nprint(user_id_map[user])\nuser_index = user_id_map[user]\n\nuser_input = np.array([user_index])\nitem_inputs = np.array(list(item_id_map.values()))\nitem_ratings = model.predict([user_input, item_inputs, np.zeros_like(item_inputs), np.zeros_like(item_inputs), np.zeros_like(item_inputs), np.zeros_like(item_inputs)])\ntop_items = item_ratings.flatten().argsort()[::-1][:10]\ntop_item_names = [item_ids[i] for i in top_items]\nprint(f\"Top 10 recommended teams for user {user}: {top_item_names}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:43:57.489440Z","iopub.status.idle":"2023-05-08T19:43:57.489814Z","shell.execute_reply.started":"2023-05-08T19:43:57.489636Z","shell.execute_reply":"2023-05-08T19:43:57.489655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n# Evaluate the model on the testing data\n\nmse = model.evaluate([data['name1'], data['NewTeam1'], data['age'], data['MarketValue'], data['Fee'], data['MinutesPlayed']], data['PPG'])\n\nprint(\"Mean Squared Error:\", mse)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:43:57.491146Z","iopub.status.idle":"2023-05-08T19:43:57.491576Z","shell.execute_reply.started":"2023-05-08T19:43:57.491341Z","shell.execute_reply":"2023-05-08T19:43:57.491362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['NewTeam']","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:48:19.024136Z","iopub.execute_input":"2023-05-08T19:48:19.024628Z","iopub.status.idle":"2023-05-08T19:48:19.034265Z","shell.execute_reply.started":"2023-05-08T19:48:19.024587Z","shell.execute_reply":"2023-05-08T19:48:19.033187Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0              Manchester City\n1                   Chelsea FC\n2            Manchester United\n3                   Chelsea FC\n4                  Real Madrid\n                 ...          \n30061       Twente Enschede FC\n30062           CA River Plate\n30063        Charlton Athletic\n30064           FK Jablonec 97\n30065    FC Sochaux-Montb?iard\nName: NewTeam, Length: 30066, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\n# Load the data\ndata = pd.read_csv(\"/kaggle/input/mydata/MYDATA.csv\")\n\n# Encode the categorical features\nle = LabelEncoder()\ndata[\"team_encoded\"] = le.fit_transform(data[\"NewTeam\"])\ndata[\"position_encoded\"] = le.fit_transform(data[\"position\"])\n\n# Normalize the numerical features\ndata[\"transfer_fee_norm\"] = (data[\"Fee\"] - data[\"Fee\"].min()) / (data[\"Fee\"].max() - data[\"Fee\"].min())\ndata[\"age_norm\"] = (data[\"age\"] - data[\"age\"].min()) / (data[\"age\"].max() - data[\"age\"].min())\n\n# Compute the player similarities based on their attributes\nplayer_attrs = [\"team_encoded\", \"position_encoded\", \"transfer_fee_norm\", \"age_norm\"]\nplayer_attr_matrix = data[player_attrs].to_numpy()\nplayer_similarities = cosine_similarity(player_attr_matrix)\n\n# Define a function to get the top-k similar players\ndef get_top_k_similar_players(player_id, k):\n    similarities = player_similarities[player_id]\n    top_k_indices = similarities.argsort()[::-1][1:k+1]\n    top_k_players = data.iloc[top_k_indices][\"name\"].values\n    return top_k_players\n\n# Define a function to get the top-k recommended players for a new team, transfer fee, position, and age\ndef get_top_k_recommended_players(new_team, transfer_fee, position, age, k):\n    # Encode the input features\n    new_team_encoded = le.transform([new_team])[0]\n    position_encoded = le.transform([position])[0]\n    transfer_fee_norm = (transfer_fee - data[\"Fee\"].min()) / (data[\"Fee\"].max() - data[\"Fee\"].min())\n    age_norm = (age - data[\"age\"].min()) / (data[\"age\"].max() - data[\"age\"].min())\n\n    # Compute the player similarities based on the input features\n    input_player_attrs = np.array([new_team_encoded, position_encoded, transfer_fee_norm, age_norm]).reshape(1, -1)\n    input_player_attrs_norm = (input_player_attrs - player_attr_matrix.min(axis=0)) / (player_attr_matrix.max(axis=0) - player_attr_matrix.min(axis=0))\n    input_player_similarities = cosine_similarity(np.concatenate([player_attr_matrix_norm, input_player_attrs_norm], axis=0))\n    input_player_similarities = input_player_similarities[:-1]\n\n    # Combine the collaborative filtering and content-based filtering scores\n    scores = player_similarities * input_player_similarities\n    scores = np.sum(scores, axis=0)\n\n    # Get the top-k recommended players\n    top_k_indices = scores.argsort()[::-1][0:k]\n    top_k_players = data.iloc[top_k_indices][\"name\"].values\n    return top_k_players\n\n# Test the recommendation system\nnew_team = \"Manchester United\"\ntransfer_fee = 100000000\nposition = \"Forward\"\nage = 25\nk = 10\nprint(f\"Top-{k} recommended players for {new_team}, {transfer_fee}, {position}, {age}:\")\nrecommended_players = get_top_k_recommended_players(new_team, transfer_fee, position, age, k)\nfor i, player in enumerate(recommended_players):\n    print(f\"{i+1}. {player}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T19:51:08.053988Z","iopub.execute_input":"2023-05-08T19:51:08.054461Z","iopub.status.idle":"2023-05-08T19:51:13.656024Z","shell.execute_reply.started":"2023-05-08T19:51:08.054423Z","shell.execute_reply":"2023-05-08T19:51:13.654346Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Top-10 recommended players for Manchester United, 100000000, Forward, 25:\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nandict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Manchester United'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/520626.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Top-{k} recommended players for {new_team}, {transfer_fee}, {position}, {age}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mrecommended_players\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_top_k_recommended_players\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_team\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransfer_fee\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommended_players\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{i+1}. {player}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/520626.py\u001b[0m in \u001b[0;36mget_top_k_recommended_players\u001b[0;34m(new_team, transfer_fee, position, age, k)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_top_k_recommended_players\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_team\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransfer_fee\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# Encode the input features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mnew_team_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_team\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mposition_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtransfer_fee_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtransfer_fee\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Fee\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Fee\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Fee\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_map_to_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"y contains previously unseen labels: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_unknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 'Manchester United'"],"ename":"ValueError","evalue":"y contains previously unseen labels: 'Manchester United'","output_type":"error"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\n# Load the data\ndata = pd.read_csv(\"/kaggle/input/mydata/MYDATA.csv\")\n\n# Encode the categorical features\nle_team = LabelEncoder()\nle_position = LabelEncoder()\nle_team.fit(data[\"NewTeam\"])\nle_position.fit(data[\"position\"])\ndata[\"team_encoded\"] = le_team.transform(data[\"NewTeam\"])\ndata[\"position_encoded\"] = le_position.transform(data[\"position\"])\n\n# Normalize the numerical features\ndata[\"transfer_fee_norm\"] = (data[\"Fee\"] - data[\"Fee\"].min()) / (data[\"Fee\"].max() - data[\"Fee\"].min())\ndata[\"age_norm\"] = (data[\"age\"] - data[\"age\"].min()) / (data[\"age\"].max() - data[\"age\"].min())\n\n# Compute the player similarities based on their attributes\nplayer_attrs = [\"team_encoded\", \"position_encoded\", \"transfer_fee_norm\", \"age_norm\"]\nplayer_attr_matrix = data[player_attrs].to_numpy()\nplayer_similarities = cosine_similarity(player_attr_matrix)\n\n# Define a function to get the top-k similar players\ndef get_top_k_similar_players(player_id, k):\n    similarities = player_similarities[player_id]\n    top_k_indices = similarities.argsort()[::-1][1:k+1]\n    top_k_players = data.iloc[top_k_indices][\"name\"].values\n    return top_k_players\n\n# Define a function to get the top-k recommended players for a new team, transfer fee, position, and age\ndef get_top_k_recommended_players(new_team, transfer_fee, position, age, k):\n    # Encode the input features\n    new_team_encoded = le_team.transform([new_team])[0]\n    position_encoded = le_position.transform([position])[0]\n    transfer_fee_norm = (transfer_fee - data[\"Fee\"].min()) / (data[\"Fee\"].max() - data[\"Fee\"].min())\n    age_norm = (age - data[\"age\"].min()) / (data[\"age\"].max() - data[\"age\"].min())\n    \n    # Compute the player similarities based on the input features\n    input_player_attrs = np.array([new_team_encoded, position_encoded, transfer_fee_norm, age_norm]).reshape(1, -1)\n    input_player_similarities = cosine_similarity(np.concatenate([player_attr_matrix, input_player_attrs], axis=0))\n    input_player_similarities = input_player_similarities[:-1,1:]\n    \n    # Combine the collaborative filtering and content-based filtering scores\n    scores = player_similarities * input_player_similarities\n    scores = np.sum(scores, axis=0)\n    \n    # Get the top-k recommended players\n    top_k_indices = scores.argsort()[::-1][0:k]\n    top_k_players = data.iloc[top_k_indices][\"name\"].values\n    return top_k_players\n\n# Test the recommendation system\nnew_team = \"Liverpool FC\"\ntransfer_fee = 30.0\nposition = \"Centre-Back\"\nage = 25\nk = 10\nprint(f\"Top-{k} recommended players for {new_team}, {transfer_fee}, {position}, {age}:\")\nrecommended_players = get_top_k_recommended_players(new_team, transfer_fee, position, age, k)\nfor i, player in enumerate(recommended_players):\n    print(f\"{i+1}. {player}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T20:17:25.764348Z","iopub.execute_input":"2023-05-08T20:17:25.765484Z","iopub.status.idle":"2023-05-08T20:17:42.761189Z","shell.execute_reply.started":"2023-05-08T20:17:25.765438Z","shell.execute_reply":"2023-05-08T20:17:42.759868Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Top-10 recommended players for Liverpool FC, 30.0, Centre-Back, 25:\n1. Fernando Gaibor \n2. Efra? Velarde \n3. Mauro Manotas \n4. Diego Forl? \n5. Yannick Bolasie \n6. Georgi Peev \n7. Mariano Pern? \n8. Antonio Blanco \n9. Karlo Bartolec \n10. Pedro Rocha \n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Concatenate, Dense\nfrom tensorflow.keras.models import Model\n\n# Load the data\ndata = pd.read_csv(\"/kaggle/input/mydata/MYDATA.csv\")\n\n# Encode the categorical features\nle = LabelEncoder()\ndata[\"team_encoded\"] = le.fit_transform(data[\"NewTeam\"])\ndata[\"position_encoded\"] = le.fit_transform(data[\"position\"])\nn_teams = len(le.classes_)\nn_positions = len(data[\"position\"].unique())\n\n# Normalize the numerical features\ndata[\"transfer_fee_norm\"] = (data[\"Fee\"] - data[\"Fee\"].min()) / (data[\"Fee\"].max() - data[\"Fee\"].min())\ndata[\"age_norm\"] = (data[\"age\"] - data[\"age\"].min()) / (data[\"age\"].max() - data[\"age\"].min())\n\n# Split the data into training and validation sets\ntrain_data = data.sample(frac=0.8, random_state=42)\nval_data = data.drop(train_data.index)\n\n\n\n# Define the model\nteam_input = Input(shape=(1,), name=\"team_input\")\nteam_embedding = Embedding(n_teams, 16, name=\"team_embedding\")(team_input)\nteam_flattened = Flatten(name=\"team_flattened\")(team_embedding)\n\nposition_input = Input(shape=(1,), name=\"position_input\")\nposition_embedding = Embedding(n_positions, 8, name=\"position_embedding\")(position_input)\nposition_flattened = Flatten(name=\"position_flattened\")(position_embedding)\n\ntransfer_fee_input = Input(shape=(1,), name=\"transfer_fee_input\")\nage_input = Input(shape=(1,), name=\"age_input\")\n\nconcatenated = Concatenate(name=\"concatenated\")([team_flattened, position_flattened, transfer_fee_input, age_input])\ndense1 = Dense(64, activation=\"relu\", name=\"dense1\")(concatenated)\ndense2 = Dense(32, activation=\"relu\", name=\"dense2\")(dense1)\noutput = Dense(1, activation=\"sigmoid\", name=\"output\")(dense2)\n\nmodel = Model(inputs=[team_input, position_input, transfer_fee_input, age_input], outputs=output)\n\n# Compile the model\nmodel.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n\n# Train the model\nhistory = model.fit(\n    [train_data[\"team_encoded\"], train_data[\"position_encoded\"], train_data[\"transfer_fee_norm\"], train_data[\"age_norm\"]],\n    train_data[\"PPG\"],\n    validation_data=(\n        [val_data[\"team_encoded\"], val_data[\"position_encoded\"], val_data[\"transfer_fee_norm\"], val_data[\"age_norm\"]],\n        val_data[\"PPG\"],\n    ),\n    \n    epochs=10,\n    batch_size=64,\n)\n# Define a function to get the top-k recommended players for a new team, transfer fee, position, and age\n# Define a function to get the top-k recommended players for a new team, transfer fee, position, and age\ndef get_top_k_recommended_players(new_team, transfer_fee, position, age, k):\n    # Encode the input features\n    new_team_encoded = le.transform([new_team])[0]\n    position_encoded = le.transform([position])[0]\n    transfer_fee_norm = (transfer_fee - data[\"transfer_fee\"].min()) / (data[\"transfer_fee\"].max() - data[\"transfer_fee\"].min())\n    age_norm = (age - data[\"age\"].min()) / (data[\"age\"].max() - data[\"age\"].min())\n    if new_team not in team_vocab:\n        raise ValueError(\"Invalid team name\")\n\n    new_team_encoded = le.transform([new_team])[0]\n    # Check if the new_team_encoded is a valid index\n    \n    if new_team_encoded >= len(team_vocab):\n        raise ValueError(\"Invalid team index\")\n\n    team_embedding = model.get_layer(\"team_embedding\")\n    #team_embed = team_embedding(tf.constant([new_team_encoded]))\n\n    # Compute the predicted target values for the input features\n    input_data = np.array([[new_team_encoded, position_encoded, transfer_fee_norm, age_norm]])\n    target_values = model.predict(input_data)\n\n    # Get the indices of the top-k recommended players\n    indices = np.argsort(-target_values)[0][:k]\n\n    # Map the indices to player names and return the list of recommended players\n    recommended_players = [player_names[i] for i in indices]\n    return recommended_players\nnew_team = \"Liverpool FC\"\ntransfer_fee = 30.0\nposition = \"Centre-Back\"\nage = 25\nk = 10\nprint(f\"Top-{k} recommended players for {new_team}, {transfer_fee}, {position}, {age}:\")\nrecommended_players = get_top_k_recommended_players(new_team, transfer_fee, position, age, k)\nfor i, player in enumerate(recommended_players):\n    print(f\"{i+1}. {player}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T20:22:19.834275Z","iopub.execute_input":"2023-05-08T20:22:19.835636Z","iopub.status.idle":"2023-05-08T20:22:21.332809Z","shell.execute_reply.started":"2023-05-08T20:22:19.835574Z","shell.execute_reply":"2023-05-08T20:22:21.330805Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1508437261.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m )\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Define a function to get the top-k recommended players for a new team, transfer fee, position, and age\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_7/team_embedding/embedding_lookup' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_27/1508437261.py\", line 60, in <module>\n      batch_size=64,\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/layers/core/embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_7/team_embedding/embedding_lookup'\nindices[0,0] = 1214 is not in [0, 16)\n\t [[{{node model_7/team_embedding/embedding_lookup}}]] [Op:__inference_train_function_9051]"],"ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node 'model_7/team_embedding/embedding_lookup' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/opt/conda/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.7/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"/opt/conda/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_27/1508437261.py\", line 60, in <module>\n      batch_size=64,\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/layers/core/embedding.py\", line 208, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'model_7/team_embedding/embedding_lookup'\nindices[0,0] = 1214 is not in [0, 16)\n\t [[{{node model_7/team_embedding/embedding_lookup}}]] [Op:__inference_train_function_9051]","output_type":"error"}]},{"cell_type":"code","source":"# Test the recommendation system\nnew_team = \"Manchester United\"\ntransfer_fee = 30.0\nposition = \"Centre-Back\"\nage = 25\nk = 10\nprint(f\"Top-{k} recommended players for {new_team}, {transfer_fee}, {position}, {age}:\")\nrecommended_players = get_top_k_recommended_players(new_team, transfer_fee, position, age, k)\nfor i, player in enumerate(recommended_players):\n    print(f\"{i+1}. {player}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Embedding, Concatenate, Dense\nfrom tensorflow.keras.models import Model\nfrom sklearn.preprocessing import LabelEncoder\n\n# Load the data\ndata = pd.read_csv(\"/kaggle/input/mydata/MYDATA.csv\")\n\n# Define the input features\nnum_features = ['age', 'MarketValue', 'Fee', 'YearOfTranfert', 'Height', 'Squad', 'Appearances', 'PPG', 'Goals', 'Assists', 'OwnGoals', 'SubsON', 'SubsOFF', 'YellowCards', 'SecondYellowCards', 'RedCards', 'PenaltyGoals', 'MinutesPerGoal', 'MinutesPlayed']\ncat_features = ['position', 'Country', 'PreviousTeam', 'LeagueOfPreviousTeam', 'CountryOfPreviousTeam', 'NewTeam', 'LeagueOfNewTeam', 'CountryOfNewTeam', 'PlaceOfBirth']\n\n# Encode the categorical features\ncat_encoders = {}\nfor feature in cat_features:\n    cat_encoders[feature] = LabelEncoder()\n    data[feature] = cat_encoders[feature].fit_transform(data[feature])\n\n# Define the embedding sizes for each categorical feature\nembedding_sizes = [(len(cat_encoders[feature].classes_), min(50, (len(cat_encoders[feature].classes_) + 1) // 2)) for feature in cat_features]\n\n# Define the input tensors\nnum_inputs = Input(shape=(len(num_features),))\ncat_inputs = [Input(shape=(1,)) for i in range(len(cat_features))]\n\n# Define the embedding layers for the categorical features\ncat_embeddings = []\nfor i in range(len(cat_features)):\n    cat_embedding = Embedding(input_dim=embedding_sizes[i][0], output_dim=embedding_sizes[i][1], name=f\"{cat_features[i]}_embedding\")(cat_inputs[i])\n    cat_embedding = tf.squeeze(cat_embedding, axis=1)\n    cat_embeddings.append(cat_embedding)\n\n# Concatenate the input tensors\nx = Concatenate()([num_inputs] + cat_embeddings)\n\n# Define the output tensor\noutput = Dense(1, activation='linear')(x)\n\n# Define the model\nmodel = Model(inputs=[num_inputs] + cat_inputs, outputs=output)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Train the model\nmodel.fit([data[num_features]] + [data[cat_feature].values for cat_feature in cat_features], data['MinutesPlayed'], epochs=10, batch_size=32, validation_split=0.2)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T20:28:39.113238Z","iopub.execute_input":"2023-05-08T20:28:39.113669Z","iopub.status.idle":"2023-05-08T20:29:22.746816Z","shell.execute_reply.started":"2023-05-08T20:28:39.113632Z","shell.execute_reply":"2023-05-08T20:29:22.745887Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/10\n752/752 [==============================] - 7s 6ms/step - loss: 1010404.4375 - val_loss: 270504.8125\nEpoch 2/10\n752/752 [==============================] - 4s 5ms/step - loss: 198533.5312 - val_loss: 137211.7500\nEpoch 3/10\n752/752 [==============================] - 4s 5ms/step - loss: 87589.1094 - val_loss: 52060.6367\nEpoch 4/10\n752/752 [==============================] - 4s 5ms/step - loss: 27573.6680 - val_loss: 13105.1982\nEpoch 5/10\n752/752 [==============================] - 4s 5ms/step - loss: 5493.1772 - val_loss: 2217.5227\nEpoch 6/10\n752/752 [==============================] - 4s 5ms/step - loss: 865.4136 - val_loss: 503.6617\nEpoch 7/10\n752/752 [==============================] - 4s 5ms/step - loss: 304.7435 - val_loss: 254.1408\nEpoch 8/10\n752/752 [==============================] - 4s 5ms/step - loss: 187.7767 - val_loss: 160.1904\nEpoch 9/10\n752/752 [==============================] - 4s 5ms/step - loss: 120.2845 - val_loss: 113.8726\nEpoch 10/10\n752/752 [==============================] - 4s 5ms/step - loss: 75.1319 - val_loss: 70.3127\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x77e9fc266ed0>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Define and fit the scaler object\nscaler = MinMaxScaler()\n\n# Transform the new data\nnew_data = pd.DataFrame({\n    'age': [25],\n    'position': ['FW'],\n    'Country': ['Spain'],\n    'MarketValue': [50000000],\n    'PreviousTeam': ['Barcelona'],\n    'LeagueOfPreviousTeam': ['La Liga'],\n    'CountryOfPreviousTeam': ['Spain'],\n    'Fee': [60000000],\n    'YearOfTranfert': [2021],\n    'NewTeam': ['Paris Saint-Germain'],\n    'LeagueOfNewTeam': ['Ligue 1'],\n    'CountryOfNewTeam': ['France'],\n    'Height': [180],\n    'Squad': [23],\n    'Appearances': [30],\n    'PPG': [0.9],\n    'Goals': [25],\n    'Assists': [10],\n    'OwnGoals': [0],\n    'SubsON': [5],\n    'SubsOFF': [2],\n    'YellowCards': [2],\n    'SecondYellowCards': [0],\n    'RedCards': [1],\n    'PenaltyGoals': [2]\n})\nfrom sklearn.preprocessing import LabelEncoder\n\n# Create a LabelEncoder object for each categorical feature\nle_position = LabelEncoder()\nle_country = LabelEncoder()\nle_previous_team = LabelEncoder()\nle_league_previous_team = LabelEncoder()\nle_country_previous_team = LabelEncoder()\nle_new_team = LabelEncoder()\nle_league_new_team = LabelEncoder()\nle_country_new_team = LabelEncoder()\n\n# Encode the categorical features in the new_data DataFrame\nnew_data['position'] = le_position.fit_transform(new_data['position'])\nnew_data['Country'] = le_country.fit_transform(new_data['Country'])\nnew_data['PreviousTeam'] = le_previous_team.fit_transform(new_data['PreviousTeam'])\nnew_data['LeagueOfPreviousTeam'] = le_league_previous_team.fit_transform(new_data['LeagueOfPreviousTeam'])\nnew_data['CountryOfPreviousTeam'] = le_country_previous_team.fit_transform(new_data['CountryOfPreviousTeam'])\nnew_data['NewTeam'] = le_new_team.fit_transform(new_data['NewTeam'])\nnew_data['LeagueOfNewTeam'] = le_league_new_team.fit_transform(new_data['LeagueOfNewTeam'])\nnew_data['CountryOfNewTeam'] = le_country_new_team.fit_transform(new_data['CountryOfNewTeam'])\n\n# Print the encoded new_data DataFrame\nprint(new_data)\n\n\npredictions = model.predict(new_data)\n\nprint(f\"Predicted market value: {predictions[0][0]:,.2f} euros\")\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T20:34:29.633497Z","iopub.execute_input":"2023-05-08T20:34:29.633961Z","iopub.status.idle":"2023-05-08T20:34:29.809744Z","shell.execute_reply.started":"2023-05-08T20:34:29.633919Z","shell.execute_reply":"2023-05-08T20:34:29.808129Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"   age  position  Country  MarketValue  PreviousTeam  LeagueOfPreviousTeam  \\\n0   25         0        0     50000000             0                     0   \n\n   CountryOfPreviousTeam       Fee  YearOfTranfert  NewTeam  ...  PPG  Goals  \\\n0                      0  60000000            2021        0  ...  0.9     25   \n\n   Assists  OwnGoals  SubsON  SubsOFF  YellowCards  SecondYellowCards  \\\n0       10         0       5        2            2                  0   \n\n   RedCards  PenaltyGoals  \n0         1             2  \n\n[1 rows x 25 columns]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/3588287178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicted market value: {predictions[0][0]:,.2f} euros\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 217, in assert_input_compatibility\n        f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_8\" expects 10 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 25) dtype=float64>]\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 217, in assert_input_compatibility\n        f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_8\" expects 10 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 25) dtype=float64>]\n","output_type":"error"}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom tensorflow import keras\n\n# Load data\ndata = pd.read_csv(\"/kaggle/input/mydata/MYDATA.csv\")\n\n\n# Encode categorical features\ncat_cols = ['position', 'Country', 'PreviousTeam', 'LeagueOfPreviousTeam',\n            'CountryOfPreviousTeam', 'NewTeam', 'LeagueOfNewTeam', 'CountryOfNewTeam',\n            'PlaceOfBirth']\nfor col in cat_cols:\n    le = LabelEncoder()\n    data[col] = le.fit_transform(data[col])\n\nencoders = dict()\nfor cat in cat_cols:\n    encoders[cat] = LabelEncoder()\n    data[f'{cat}_n'] = encoders[cat].fit_transform(data[cat])    \n    \n    \n# Split into input (X) and output (y) variables\nX = data.drop(['name', 'MarketValue'], axis=1)\ny = data['MarketValue']\n\n# Scale input variables\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Define and fit the model\nmodel = keras.Sequential([\n    keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1],)),\n    keras.layers.Dense(64, activation='relu'),\n    keras.layers.Dense(1)\n])\nmodel.compile(optimizer='adam', loss='mean_squared_error')\nmodel.fit(X, y, epochs=10, batch_size=32)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T21:32:50.177478Z","iopub.execute_input":"2023-05-08T21:32:50.177943Z","iopub.status.idle":"2023-05-08T21:33:10.633928Z","shell.execute_reply.started":"2023-05-08T21:32:50.177900Z","shell.execute_reply":"2023-05-08T21:33:10.632263Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Epoch 1/10\n940/940 [==============================] - 3s 2ms/step - loss: 19.2268\nEpoch 2/10\n940/940 [==============================] - 2s 2ms/step - loss: 15.4137\nEpoch 3/10\n940/940 [==============================] - 2s 2ms/step - loss: 14.8182\nEpoch 4/10\n940/940 [==============================] - 2s 2ms/step - loss: 14.4197\nEpoch 5/10\n940/940 [==============================] - 2s 2ms/step - loss: 13.9504\nEpoch 6/10\n940/940 [==============================] - 2s 2ms/step - loss: 13.6575\nEpoch 7/10\n940/940 [==============================] - 2s 2ms/step - loss: 13.2892\nEpoch 8/10\n940/940 [==============================] - 2s 2ms/step - loss: 12.8065\nEpoch 9/10\n940/940 [==============================] - 2s 2ms/step - loss: 12.5722\nEpoch 10/10\n940/940 [==============================] - 2s 2ms/step - loss: 12.1997\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x76bd7c539d10>"},"metadata":{}}]},{"cell_type":"code","source":"data1 = pd.read_csv(\"/kaggle/input/mydata/MYDATA.csv\")\n\ndata1['LeagueOfPreviousTeam']","metadata":{"execution":{"iopub.status.busy":"2023-05-08T21:33:10.636007Z","iopub.execute_input":"2023-05-08T21:33:10.636531Z","iopub.status.idle":"2023-05-08T21:33:10.826293Z","shell.execute_reply.started":"2023-05-08T21:33:10.636491Z","shell.execute_reply":"2023-05-08T21:33:10.824583Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0            Bundesliga\n1         Liga Portugal\n2            Eredivisie\n3        Premier League\n4               Ligue 1\n              ...      \n30061        A' Ethniki\n30062           Ligue 1\n30063      Serie C1 - B\n30064           Ligue 1\n30065           Ligue 2\nName: LeagueOfPreviousTeam, Length: 30066, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"# Create new data for prediction\nnew_data = pd.DataFrame({\n    'age': [25],\n    'position': ['Centre-Forward'],\n    'Country': ['Spain'],\n    'PreviousTeam': ['Barcelona'],\n    'LeagueOfPreviousTeam': ['Bundesliga'],\n    'CountryOfPreviousTeam': ['Spain'],\n    'Fee': [60000000],\n    'YearOfTranfert': [2021],\n    'NewTeam': ['Paris Saint-Germain'],\n    'LeagueOfNewTeam': ['Ligue 1'],\n    'CountryOfNewTeam': ['France'],\n    'Height': [180],\n    'Squad': [23],\n    'Appearances': [30],\n    'PPG': [0.9],\n    'Goals': [25],\n    'Assists': [10],\n    'OwnGoals': [0],\n    'SubsON': [5],\n    'SubsOFF': [2],\n    'YellowCards': [2],\n    'SecondYellowCards': [0],\n    'RedCards': [1],\n    'PenaltyGoals': [2],\n    'MinutesPerGoal': [90],\n    'MinutesPlayed': [2700],\n    'PlaceOfBirth': ['Madrid']\n})\n\ncat_cols = ['position', 'Country', 'PreviousTeam', 'LeagueOfPreviousTeam', 'CountryOfPreviousTeam', 'NewTeam', 'LeagueOfNewTeam', 'CountryOfNewTeam', 'PlaceOfBirth']\n\nencoders = dict()\nfor cat in cat_cols:\n    encoders[cat] = LabelEncoder()\n    new_data[f'{cat}_n'] = encoders[cat].fit_transform(new_data[cat])\n\nscaler = StandardScaler()\nnew_data_n = scaler.fit_transform(new_data_n)\n\nnew_data_n = new_data.drop(['position', 'Country', 'PreviousTeam', 'LeagueOfPreviousTeam', 'CountryOfPreviousTeam', 'NewTeam', 'LeagueOfNewTeam', 'CountryOfNewTeam', 'PlaceOfBirth'], axis='columns')\nnew_data_tf = tf.convert_to_tensor(new_data , dtype=tf.int32)\n\n# Make predictions\npredictions = model.predict(new_data)\nprint(predictions)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T21:39:43.431822Z","iopub.execute_input":"2023-05-08T21:39:43.432282Z","iopub.status.idle":"2023-05-08T21:39:43.495975Z","shell.execute_reply.started":"2023-05-08T21:39:43.432239Z","shell.execute_reply":"2023-05-08T21:39:43.492943Z"},"trusted":true},"execution_count":14,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1525422639.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mnew_data_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'position'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Country'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PreviousTeam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LeagueOfPreviousTeam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CountryOfPreviousTeam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'NewTeam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LeagueOfNewTeam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CountryOfNewTeam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PlaceOfBirth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mnew_data_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'Centre-Forward'"],"ename":"ValueError","evalue":"invalid literal for int() with base 10: 'Centre-Forward'","output_type":"error"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import plot_model\n\n# Load data\ndf = pd.read_csv('/kaggle/input/mydata/MYDATA.csv')\n\n# Define features for model\nfeatures = ['age', 'position', 'Country', 'MarketValue', 'PreviousTeam', 'LeagueOfPreviousTeam',            'CountryOfPreviousTeam', 'Fee', 'YearOfTranfert', 'NewTeam', 'LeagueOfNewTeam',            'CountryOfNewTeam', 'Height', 'Squad', 'Appearances', 'PPG', 'Goals', 'Assists',            'OwnGoals', 'SubsON', 'SubsOFF', 'YellowCards', 'SecondYellowCards', 'RedCards',            'PenaltyGoals']\n\n# Apply label encoding to categorical features\nlabel_encoders = {}\nfor feature in ['position', 'Country', 'PreviousTeam', 'LeagueOfPreviousTeam', 'CountryOfPreviousTeam',                'NewTeam', 'LeagueOfNewTeam', 'CountryOfNewTeam']:\n    label_encoders[feature] = LabelEncoder()\n    df[feature] = label_encoders[feature].fit_transform(df[feature])\n\n# Apply min-max scaling to numerical features\nscaler = MinMaxScaler()\ndf[features] = scaler.fit_transform(df[features])\n\n# Define model architecture\ninput_layers = []\nencoded_layers = []\nfor feature in features:\n    input_layer = Input(shape=(1,))\n    encoded_layer = Dense(16, activation='relu')(input_layer)\n    input_layers.append(input_layer)\n    encoded_layers.append(encoded_layer)\nmerged_layer = Concatenate()(encoded_layers)\ndropout_layer = Dropout(0.2)(merged_layer)\noutput_layer = Dense(1, activation='linear')(dropout_layer)\nmodel = Model(inputs=input_layers, outputs=output_layer)\nmodel.compile(optimizer='adam', loss='mse')\n\n# Train model\nX = [df[feature].values for feature in features]\ny = df['MarketValue'].values\nmodel.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T21:56:47.502122Z","iopub.execute_input":"2023-05-08T21:56:47.502521Z","iopub.status.idle":"2023-05-08T21:57:33.873616Z","shell.execute_reply.started":"2023-05-08T21:56:47.502486Z","shell.execute_reply":"2023-05-08T21:57:33.872392Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/10\n752/752 [==============================] - 9s 6ms/step - loss: 0.0018 - val_loss: 3.7388e-05\nEpoch 2/10\n752/752 [==============================] - 4s 6ms/step - loss: 1.7020e-04 - val_loss: 3.1448e-05\nEpoch 3/10\n752/752 [==============================] - 4s 5ms/step - loss: 1.2489e-04 - val_loss: 1.0705e-05\nEpoch 4/10\n752/752 [==============================] - 4s 6ms/step - loss: 1.1718e-04 - val_loss: 1.2695e-05\nEpoch 5/10\n752/752 [==============================] - 4s 6ms/step - loss: 1.1309e-04 - val_loss: 3.8080e-05\nEpoch 6/10\n752/752 [==============================] - 4s 5ms/step - loss: 1.1794e-04 - val_loss: 1.9599e-05\nEpoch 7/10\n752/752 [==============================] - 4s 5ms/step - loss: 1.1087e-04 - val_loss: 1.0681e-05\nEpoch 8/10\n752/752 [==============================] - 4s 5ms/step - loss: 1.2425e-04 - val_loss: 1.4524e-05\nEpoch 9/10\n752/752 [==============================] - 4s 5ms/step - loss: 1.0168e-04 - val_loss: 1.5899e-05\nEpoch 10/10\n752/752 [==============================] - 4s 5ms/step - loss: 1.1117e-04 - val_loss: 2.1234e-05\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x76bd75456210>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nstandard_scalers = {}\n# Use model for recommendations\nnew_data = pd.DataFrame({\n    'age': [25],\n    'position': ['Left-Back'],\n    'Country': ['Spain'],\n    'MarketValue': [28],\n    'PreviousTeam': ['Brighton & Hove Albion'],\n    'LeagueOfPreviousTeam': ['Premier League'],\n    'CountryOfPreviousTeam': ['England'],\n    'Fee': [65],\n    'YearOfTranfert': [2022],\n    'NewTeam': ['Chelsea FC'],\n    'LeagueOfNewTeam': ['Premier League'],\n    'CountryOfNewTeam': ['England'],\n    'Height': [173],\n    'Squad': [40],\n    'Appearances': [40],\n    'PPG': [1.2],\n    'Goals': [1],\n    'Assists': [2],\n    'OwnGoals': [0],\n    'SubsON': [3],\n    'SubsOFF': [3],\n    'YellowCards': [6],\n    'SecondYellowCards': [0],\n    'RedCards': [1],\n    'PenaltyGoals': [2]\n})\n# Encode categorical variables using the label encoder\nfor feature in ['position', 'Country', 'PreviousTeam', 'LeagueOfPreviousTeam', 'CountryOfPreviousTeam', \n                'NewTeam', 'LeagueOfNewTeam', 'CountryOfNewTeam']:\n    new_data[feature] = label_encoders[feature].transform(new_data[feature])\nfor feature in ['age', 'MarketValue', 'Fee', 'Height', 'Squad', 'Appearances', 'PPG', 'Goals', 'Assists',                 'OwnGoals', 'SubsON', 'SubsOFF', 'YellowCards', 'SecondYellowCards', 'RedCards', 'PenaltyGoals',                 'MinutesPerGoal', 'MinutesPlayed']:\n    scaler = StandardScaler()\n    scaler.fit(df[[feature]])\n    standard_scalers[feature] = scaler\n# Scale numerical variables using the standard scaler\nfor feature in ['age', 'MarketValue', 'Fee', 'Height', 'Squad', 'Appearances', 'PPG', 'Goals', 'Assists', 'OwnGoals', 'SubsON', 'SubsOFF', 'YellowCards', 'SecondYellowCards', 'RedCards', 'PenaltyGoals']:\n    new_data[feature] = standard_scalers[feature].transform(new_data[feature].values.reshape(-1, 1))\n\n# Make predictions for the new data\npredictions = model.predict(new_data)\n\n# Print the predictions\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2023-05-08T22:07:16.946832Z","iopub.execute_input":"2023-05-08T22:07:16.947265Z","iopub.status.idle":"2023-05-08T22:07:17.134906Z","shell.execute_reply.started":"2023-05-08T22:07:16.947226Z","shell.execute_reply":"2023-05-08T22:07:17.132845Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n/opt/conda/lib/python3.7/site-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n  \"X does not have valid feature names, but\"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1638190603.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Make predictions for the new data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Print the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 217, in assert_input_compatibility\n        f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model\" expects 25 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 25) dtype=float64>]\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 217, in assert_input_compatibility\n        f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model\" expects 25 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 25) dtype=float64>]\n","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}